# Daily arXiv Patrol Digest — 2026-02-23

## Scope and filtering
- **Requested window:** NEW/UPDATED in last 24h (2026-02-22 13:30 UTC → 2026-02-23 13:30 UTC), including cross-list/version updates.
- **Result in strict window:** **0 matching papers** from configured arXiv API feeds.
- **Filtering criteria used for shortlist below:** keyword match (permissions/authorization/access control; privacy/exfiltration/prompt injection/audit; memory storage/access/query/indexing/lifecycle), agent-security relevance, and likely practical impact.
- **Shortlist policy:** best-effort fallback to the **most recently updated reachable papers** (primarily 2026-02-18 to 2026-02-20) because the strict 24h window returned no hits.

## Fetch issues & fallback
- No transport/API failures from configured sources in `research/rss_feeds.md`.
- **Observed issue:** strict 24h query window produced no eligible entries for these topics.
- **Fallback applied:** selected top 10 from latest reachable relevant updates outside the strict window.

---

## Paper list

### 1) Helpful to a Fault: Measuring Illicit Assistance in Multi-Turn, Multilingual LLM Agents
- **Authors:** Nivya Talokar, Ayush K Tarun, Murari Mandal, Maksym Andriushchenko, Antoine Bosselut
- **arXiv:** `2602.16346v2` (**cs.CL**)
- **Summary:**
  - Introduces **STING**, a multi-turn red-teaming framework targeting illicit goal completion by tool-using, memory-enabled agents.
  - Moves beyond single-shot jailbreak tests by modeling progressive, persona-grounded attack trajectories.
  - Uses adaptive probing with judge agents to measure phase completion and escalation behavior.
  - Frames multi-turn compromise as a **time-to-first-jailbreak** variable.
  - Adds analysis tools such as discovery curves and language-conditioned hazard attribution.
  - Empirically shows notable multilingual variance in misuse susceptibility.
  - Argues that static safety benchmarks understate real misuse risk in deployed agent workflows.
- **Novelty:**
  - Time-to-event framing for jailbreak success in sequential agent attacks.
  - Automated multilingual, phase-aware red-team loop for illicit assistance.
- **Security relevance:**
  - **Permissions/data:** demonstrates how tool+memory affordances can be coerced into harmful multi-step execution, informing policy gating and escalation controls.
- **Limitations / open questions:**
  - Dependence on judge-agent quality.
  - Benchmark-to-production transfer for domain-specific tools remains uncertain.
  - Need stronger causal attribution of which guardrails fail first.
- **Tags:** `agent-misuse`, `multilingual-redteam`, `jailbreak`, `tool-use`, `safety-evaluation`

### 2) IntentMiner: Intent Inversion Attack via Tool Call Analysis in the Model Context Protocol
- **Authors:** Yunhao Yao, Zhiqiang Wang, Haoran Cheng, Yihang Cheng, Haohua Du, Xiang-Yang Li
- **arXiv:** `2512.14166v2` (**cs.CR**)
- **Summary:**
  - Identifies a privacy channel in MCP-style architectures: intent reconstruction from tool-call metadata.
  - Shows semi-honest tool servers can infer user intent without direct raw prompt access.
  - Proposes **IntentMiner**, a hierarchical semantic parser over function signatures, arguments, and receipts.
  - Reconstructs step-level goals from authorized protocol artifacts.
  - Highlights trust-boundary fracture introduced by modular agent-tool ecosystems.
  - Provides evidence that protocol metadata itself can be highly sensitive.
  - Motivates metadata minimization and stronger protocol-level privacy controls.
- **Novelty:**
  - Formalized “intent inversion” attack surface at MCP metadata layer.
  - Step-level intent recovery pipeline from tool traces.
- **Security relevance:**
  - **Data/privacy + permissions:** shows authorized access can still leak unauthorized intent semantics, impacting least-privilege protocol design.
- **Limitations / open questions:**
  - Defense overhead under real-time latency constraints.
  - Generalization across heterogeneous MCP tool schemas.
  - Need standardized privacy-preserving telemetry formats.
- **Tags:** `MCP`, `intent-inference`, `metadata-leakage`, `privacy`, `tool-calling`

### 3) What Makes a Good LLM Agent for Real-world Penetration Testing?
- **Authors:** Gelei Deng, Yi Liu, Yuekang Li, Ruozhao Yang, Xiaofei Xie, Jie Zhang, Han Qiu, Tianwei Zhang
- **arXiv:** `2602.17622v1` (**cs.CR**)
- **Summary:**
  - Compares 28 pentest-agent systems and deeply evaluates 5 implementations across 3 benchmarks.
  - Distinguishes **Type A** failures (engineering/tooling gaps) from **Type B** failures (planning/state issues).
  - Finds Type B errors persist across base models, indicating orchestration-level bottlenecks.
  - Attributes many collapses to missing online difficulty estimation and poor branch budgeting.
  - Proposes design principles (via Excalibur) for improved resource allocation during attack chains.
  - Emphasizes that stronger raw LLMs do not automatically solve agentic planning failures.
  - Useful for secure-agent reliability testing under adversarial workflows.
- **Novelty:**
  - Failure taxonomy that separates fixable engineering debt from deeper agent-architecture limits.
  - Difficulty-aware execution analysis for practical pentest agents.
- **Security relevance:**
  - **Permissions/policy:** informs safer autonomy caps and escalation policy for offensive-security agents before granting stronger capabilities.
- **Limitations / open questions:**
  - Benchmark realism vs enterprise network complexity.
  - Potential overfitting of recommended controls to pentest domain.
- **Tags:** `pentest-agent`, `agent-reliability`, `planning-failure`, `security-eval`, `orchestration`

### 4) FENCE: A Financial and Multimodal Jailbreak Detection Dataset
- **Authors:** Mirae Kim, Seonghun Jeong, Youngjun Kwak
- **arXiv:** `2602.18154v1` (**cs.CL**)
- **Summary:**
  - Releases a bilingual (Korean/English) multimodal dataset for finance-domain jailbreak detection.
  - Targets text+image attack surfaces in VLM deployments where harm tolerance is low.
  - Includes domain-grounded threat prompts rather than generic adversarial templates.
  - Reports measurable attack success even on strong commercial systems.
  - Baseline detector reaches high in-distribution performance and transfers to external sets.
  - Offers a reproducible benchmark for multimodal red-team pipelines.
  - Highlights underdeveloped domain-specific jailbreak datasets.
- **Novelty:**
  - Finance-focused, bilingual multimodal jailbreak corpus.
  - Cross-benchmark transfer evidence for a practical detector baseline.
- **Security relevance:**
  - **Data/security:** strengthens evaluation of multimodal prompt-injection/jailbreak defense in regulated environments.
- **Limitations / open questions:**
  - Domain specificity may limit generalization beyond finance.
  - Need longitudinal tests against adaptive attackers.
- **Tags:** `multimodal-security`, `jailbreak-detection`, `finance-LLM`, `dataset`, `red-teaming`

### 5) Towards Realistic Guarantees: A Probabilistic Certificate for SmoothLLM
- **Authors:** Adarsh Kumarappan, Ayushi Mehrotra
- **arXiv:** `2511.18721v2` (**cs.LG**)
- **Summary:**
  - Revisits certification claims of SmoothLLM under more realistic assumptions.
  - Replaces strict k-unstable condition with a probabilistic `(k, ε)-unstable` notion.
  - Derives lower bounds on defense probability informed by empirical attack behavior.
  - Evaluates across gradient-based and semantic jailbreak families.
  - Produces tunable certification thresholds aligned with deployment risk appetite.
  - Bridges gap between formal certificates and practical trust in safety guarantees.
  - Useful for selecting guardrail settings with explicit uncertainty.
- **Novelty:**
  - Probabilistic reformulation of jailbreak certification assumptions.
  - Data-informed safety bound construction for defense confidence.
- **Security relevance:**
  - **Policy/assurance:** supports risk-calibrated policy decisions instead of brittle binary guarantees.
- **Limitations / open questions:**
  - Sensitivity to attack distribution shift.
  - Certification portability across model families and updates.
- **Tags:** `certified-defense`, `jailbreak`, `probabilistic-guarantees`, `safety-assurance`, `SmoothLLM`

### 6) Jailbreaking Leaves a Trace: Understanding and Detecting Jailbreak Attacks from Internal Representations of Large Language Models
- **Authors:** Sri Durga Sai Sowmya Kadali, Evangelos E. Papalexakis
- **arXiv:** `2602.11495v2` (**cs.CR**)
- **Summary:**
  - Studies jailbreak detection via internal activations rather than prompt text alone.
  - Performs layer-wise representation analysis across multiple open models.
  - Finds separable signatures between benign and adversarial prompting trajectories.
  - Suggests internal-state detectors can complement input/output filtering.
  - Connects interpretability signals with practical security monitoring.
  - Supports possibility of model-agnostic representation-level defenses.
  - Reinforces that jailbreak behavior can leave detectable latent traces.
- **Novelty:**
  - Multi-model layer-level security analysis linking interpretability to defense.
  - Representation-space detection framing for jailbreak monitoring.
- **Security relevance:**
  - **Permissions/safety:** enables earlier risk detection before harmful tool invocation/output release.
- **Limitations / open questions:**
  - Runtime feasibility in production inference stacks.
  - Robustness against adaptive latent-space obfuscation attacks.
- **Tags:** `internal-detection`, `jailbreak`, `interpretability`, `representation-analysis`, `defense`

### 7) Large-scale online deanonymization with LLMs
- **Authors:** Simon Lermen, Daniel Paleka, Joshua Swanson, Michael Aerni, Nicholas Carlini, Florian Tramèr
- **arXiv:** `2602.16800v1` (**cs.CR**)
- **Summary:**
  - Demonstrates scalable LLM-assisted deanonymization in open- and closed-world settings.
  - Pipeline extracts identity features, retrieves candidates, and verifies matches.
  - Achieves high-precision re-identification from pseudonymous textual traces.
  - Reduces manual feature engineering burden seen in classic deanonymization work.
  - Shows that internet-enabled agent workflows materially increase re-identification risk.
  - Raises practical concerns for public logs, forums, and chat-derived corpora.
  - Suggests stricter release and telemetry minimization practices.
- **Novelty:**
  - End-to-end LLM-based identity-linking pipeline over unstructured text.
  - Demonstration of practical, high-scale operational feasibility.
- **Security relevance:**
  - **Data privacy:** direct evidence of exfiltration-style identity inference risk from seemingly non-PII traces.
- **Limitations / open questions:**
  - Ethical safeguards for releasing methods/tools.
  - Defense evaluation against style obfuscation and noise injection.
- **Tags:** `deanonymization`, `privacy-risk`, `identity-linkage`, `LLM-agents`, `data-governance`

### 8) What Do LLMs Associate with Your Name? A Human-Centered Black-Box Audit of Personal Data
- **Authors:** Dimitri Staufer, Kirsten Morehouse
- **arXiv:** `2602.17483v1` (**cs.HC**)
- **Summary:**
  - Audits personal-data association behavior across eight LLMs.
  - Introduces **LMP2**, a user-facing privacy probe tool shaped by formative studies.
  - Measures model outputs for public figures and everyday users.
  - Reports non-trivial confidence/accuracy on inferred personal attributes.
  - Studies user perception of generated personal data and trust implications.
  - Argues for transparency tools to make privacy risk legible to end users.
  - Bridges technical leakage concerns with UX and governance questions.
- **Novelty:**
  - Human-centered black-box auditing workflow for personal-data associations.
  - Tool-driven study linking model behavior to user trust/consent interpretation.
- **Security relevance:**
  - **Data governance/audit:** operationalizes privacy auditing beyond pure attack benchmarks.
- **Limitations / open questions:**
  - Coverage of non-Western naming/cultural contexts.
  - Distinguishing memorization from plausible inference in outputs.
- **Tags:** `privacy-audit`, `personal-data`, `black-box-eval`, `human-centered-security`, `governance`

### 9) MIRA: Memory-Integrated Reinforcement Learning Agent with Limited LLM Guidance
- **Authors:** Narjes Nourzad, Carlee Joe-Wong
- **arXiv:** `2602.17930v1` (**cs.LG**)
- **Summary:**
  - Proposes an RL agent that stores LLM guidance and agent experience in a structured memory graph.
  - Reduces continuous dependence on live LLM supervision by amortizing guidance into persistent memory.
  - Memory stores trajectory fragments and subgoal structures for re-use.
  - Improves learning under sparse/delayed rewards using utility-guided retrieval from memory.
  - Demonstrates a concrete memory lifecycle: write, structure, query, re-apply.
  - Offers a useful reference architecture for memory-enabled agent systems.
  - Security angle is indirect but relevant for memory governance design.
- **Novelty:**
  - Structured memory-graph integration between RL rollouts and LLM priors.
  - Practical amortization of LLM calls via persistent memory artifacts.
- **Security relevance:**
  - **Memory dimension:** clarifies where memory poisoning/provenance controls are needed in long-lived agents.
- **Limitations / open questions:**
  - No explicit adversarial-memory robustness evaluation.
  - Memory growth/garbage-collection policies under long deployments.
- **Tags:** `agent-memory`, `memory-graph`, `RL+LLM`, `retrieval`, `lifecycle`

### 10) El Agente Gráfico: Structured Execution Graphs for Scientific Agents
- **Authors:** Jiaru Bai, Abdulrahman Aldossary, Thomas Swanick, Marcel Müller, Yeonghun Kang, Zijian Zhang, Jin Won Lee, Tsz Wai Ko
- **arXiv:** `2602.17902v1` (**cs.AI**)
- **Summary:**
  - Presents a scientific-agent framework using type-safe execution and dynamic knowledge graphs.
  - Replaces fragile unstructured context handling with object-graph state representations.
  - Persists computational state externally for reproducibility and provenance.
  - Aims to reduce context overload while improving traceability of decisions.
  - Emphasizes typed interfaces for tool integration and state transitions.
  - Not a direct security paper, but materially improves auditability primitives.
  - Relevant for secure memory/indexing and controllable agent orchestration.
- **Novelty:**
  - Typed object-graph mapping for agent state and execution persistence.
  - Practical blend of LLM planning with explicit graph-backed provenance.
- **Security relevance:**
  - **Memory/access/audit:** stronger provenance and structured state can enable tighter authorization and forensics.
- **Limitations / open questions:**
  - Security controls remain mostly implicit rather than formally evaluated.
  - Integration overhead for heterogeneous production stacks.
- **Tags:** `execution-graph`, `agent-orchestration`, `provenance`, `knowledge-graph`, `memory-structure`

---

## Top 3 must-read + recommended order
1. **IntentMiner (`2512.14166v2`)**  
   Start here for a concrete, high-impact protocol-layer privacy threat (metadata-level intent leakage) with immediate design implications for MCP/tool ecosystems.
2. **Helpful to a Fault (`2602.16346v2`)**  
   Read second to understand multi-turn misuse dynamics and why single-prompt safety evals understate operational risk.
3. **Towards Realistic Guarantees (`2511.18721v2`)**  
   Read third to ground mitigation choices in probabilistic assurance instead of brittle binary claims.

## 10-line trend summary
1. Recent work is shifting from single-turn jailbreak demos to **workflow-level** agent compromise.  
2. Tool-calling architectures are exposing new leakage channels at the **protocol metadata** layer.  
3. Privacy risk is increasingly framed as **inference over traces** (intent, identity), not only explicit data dumps.  
4. There is visible momentum toward **measurement science**: hazard curves, formalized failure modes, and auditable probes.  
5. Defense papers are moving from hard assumptions to **probabilistic guarantees** better suited for deployment reality.  
6. Multimodal and domain-specific datasets (e.g., finance) are becoming central for realistic red-teaming.  
7. Memory-enabled agents are maturing architecturally, but robust **memory governance** still lags.  
8. Structured execution/state graphs are emerging as a practical path to stronger provenance and audit readiness.  
9. **Gap #1:** Few papers provide end-to-end benchmarks jointly testing permissions, memory poisoning, and data exfiltration in one suite.  
10. **Gap #2:** Need standardized, low-overhead privacy-preserving telemetry for MCP/tool ecosystems without crippling observability.
